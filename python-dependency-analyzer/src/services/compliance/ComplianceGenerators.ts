/**
 * Compliance Generators - Services de G√©n√©ration de Documentation de Conformit√©
 * 
 * G√©n√®re des documents de conformit√© pour GDPR, ISO 42001, et AI Act.
 */

import { Dependency } from '../../types';

// ========================
// GDPR Compliance Generator
// ========================

export class GDPRGenerator {
  /**
   * G√©n√®re un rapport de conformit√© GDPR
   */
  generateReport(dependencies: Dependency[]): string {
    const dataProcessingPackages = this.identifyDataProcessingPackages(dependencies);
    
    let report = '# üìã Rapport de Conformit√© GDPR\n\n';
    report += `*G√©n√©r√© le ${new Date().toLocaleString()}*\n\n`;
    
    report += '## Article 30 - Registre des Activit√©s de Traitement\n\n';
    report += '### Packages identifi√©s avec traitement de donn√©es\n\n';
    
    if (dataProcessingPackages.length === 0) {
      report += '*Aucun package de traitement de donn√©es identifi√©.*\n\n';
    } else {
      dataProcessingPackages.forEach(pkg => {
        report += `#### ${pkg.name} v${pkg.version}\n\n`;
        report += `- **Finalit√©**: ${pkg.purpose}\n`;
        report += `- **Type de donn√©es**: ${pkg.dataTypes.join(', ')}\n`;
        report += `- **Base l√©gale**: ${pkg.legalBasis}\n`;
        report += `- **Dur√©e de conservation**: ${pkg.retentionPeriod}\n`;
        report += `- **Transferts internationaux**: ${pkg.internationalTransfers ? 'Oui' : 'Non'}\n\n`;
      });
    }
    
    report += '## Article 32 - S√©curit√© du Traitement\n\n';
    report += this.generateSecurityAssessment(dependencies);
    
    report += '\n## Article 35 - Analyse d\'Impact (DPIA)\n\n';
    report += this.generateDPIARecommendations(dependencies);
    
    return report;
  }

  private identifyDataProcessingPackages(dependencies: Dependency[]) {
    const dataProcessingKeywords = [
      'database', 'sql', 'postgres', 'mysql', 'mongo', 'redis',
      'auth', 'jwt', 'oauth', 'session',
      'analytics', 'tracking', 'logging',
      'email', 'smtp', 'mail',
      'storage', 's3', 'blob'
    ];

    return dependencies
      .filter(dep => dataProcessingKeywords.some(kw => dep.name.toLowerCase().includes(kw)))
      .map(dep => ({
        name: dep.name,
        version: dep.version,
        purpose: this.inferPurpose(dep.name),
        dataTypes: this.inferDataTypes(dep.name),
        legalBasis: 'Consentement / Int√©r√™t l√©gitime (√† v√©rifier)',
        retentionPeriod: '√Ä d√©finir selon la politique',
        internationalTransfers: false
      }));
  }

  private inferPurpose(packageName: string): string {
    const purposes: Record<string, string> = {
      database: 'Stockage et gestion des donn√©es',
      auth: 'Authentification et gestion des acc√®s',
      analytics: 'Analyse et statistiques',
      email: 'Communication par email',
      storage: 'Stockage de fichiers'
    };

    for (const [key, value] of Object.entries(purposes)) {
      if (packageName.toLowerCase().includes(key)) {
        return value;
      }
    }

    return '√Ä d√©finir';
  }

  private inferDataTypes(packageName: string): string[] {
    const name = packageName.toLowerCase();
    const types: string[] = [];

    if (name.includes('auth') || name.includes('jwt')) {
      types.push('Donn√©es d\'identification');
    }
    if (name.includes('email') || name.includes('smtp')) {
      types.push('Adresses email');
    }
    if (name.includes('database') || name.includes('sql')) {
      types.push('Donn√©es personnelles vari√©es');
    }

    return types.length > 0 ? types : ['√Ä d√©finir'];
  }

  private generateSecurityAssessment(dependencies: Dependency[]): string {
    const vulnDeps = dependencies.filter(d => d.vulnerabilities && d.vulnerabilities.length > 0);
    
    let assessment = '### Mesures de S√©curit√© Techniques\n\n';
    
    if (vulnDeps.length > 0) {
      assessment += '‚ö†Ô∏è **Vuln√©rabilit√©s identifi√©es**:\n\n';
      vulnDeps.forEach(dep => {
        assessment += `- **${dep.name}**: ${dep.vulnerabilities!.length} vuln√©rabilit√©(s)\n`;
      });
      assessment += '\n**Recommandation**: Mettre √† jour ou remplacer ces packages.\n\n';
    } else {
      assessment += '‚úÖ Aucune vuln√©rabilit√© critique identifi√©e.\n\n';
    }
    
    assessment += '### Mesures Recommand√©es\n\n';
    assessment += '- Chiffrement des donn√©es au repos et en transit\n';
    assessment += '- Contr√¥le d\'acc√®s bas√© sur les r√¥les (RBAC)\n';
    assessment += '- Journalisation des acc√®s aux donn√©es personnelles\n';
    assessment += '- Pseudonymisation des donn√©es sensibles\n';
    assessment += '- Sauvegardes r√©guli√®res et chiffr√©es\n\n';
    
    return assessment;
  }

  private generateDPIARecommendations(dependencies: Dependency[]): string {
    let dpia = 'Une DPIA est recommand√©e si votre traitement implique :\n\n';
    dpia += '- ‚úÖ √âvaluation syst√©matique et automatis√©e\n';
    dpia += '- ‚úÖ Traitement √† grande √©chelle de donn√©es sensibles\n';
    dpia += '- ‚úÖ Surveillance syst√©matique\n';
    dpia += '- ‚úÖ Nouvelles technologies\n\n';
    
    const highRiskPackages = dependencies.filter(d => d.riskScore >= 6);
    if (highRiskPackages.length > 0) {
      dpia += `‚ö†Ô∏è **${highRiskPackages.length} packages √† risque √©lev√© d√©tect√©s**. Une DPIA est fortement recommand√©e.\n\n`;
    }
    
    return dpia;
  }
}

// ========================
// ISO 42001 Compliance Generator
// ========================

export class ISO42001Generator {
  /**
   * G√©n√®re un rapport de conformit√© ISO 42001 (AI Management System)
   */
  generateReport(dependencies: Dependency[]): string {
    const aiPackages = this.identifyAIPackages(dependencies);
    
    let report = '# ü§ñ Rapport de Conformit√© ISO/IEC 42001:2023\n\n';
    report += `*G√©n√©r√© le ${new Date().toLocaleString()}*\n\n`;
    
    report += '## 1. Contexte de l\'Organisation\n\n';
    report += '### Packages IA Identifi√©s\n\n';
    
    if (aiPackages.length === 0) {
      report += '*Aucun package IA identifi√©.*\n\n';
    } else {
      aiPackages.forEach(pkg => {
        report += `#### ${pkg.name} v${pkg.version}\n\n`;
        report += `- **Cat√©gorie**: ${pkg.category}\n`;
        report += `- **Risque**: ${pkg.riskScore.toFixed(1)}/10\n`;
        report += `- **Transparence**: ${pkg.explainability ? '‚úÖ' : '‚ö†Ô∏è'}\n\n`;
      });
    }
    
    report += '## 2. Leadership et Engagement\n\n';
    report += '- [ ] Politique de gestion de l\'IA d√©finie\n';
    report += '- [ ] Responsables de l\'IA d√©sign√©s\n';
    report += '- [ ] Objectifs de performance IA √©tablis\n\n';
    
    report += '## 3. Gestion des Risques IA\n\n';
    report += this.generateRiskAssessment(aiPackages);
    
    report += '## 4. Ressources\n\n';
    report += this.generateResourceRequirements(aiPackages);
    
    report += '## 5. Op√©rations\n\n';
    report += '### Cycle de Vie des Syst√®mes IA\n\n';
    report += '- [ ] Phase de conception: Sp√©cifications document√©es\n';
    report += '- [ ] Phase de d√©veloppement: Tra√ßabilit√© des d√©cisions\n';
    report += '- [ ] Phase de d√©ploiement: Tests de validation\n';
    report += '- [ ] Phase d\'exploitation: Monitoring continu\n';
    report += '- [ ] Phase de maintenance: Mises √† jour document√©es\n\n';
    
    report += '## 6. √âvaluation des Performances\n\n';
    report += this.generatePerformanceMetrics(aiPackages);
    
    return report;
  }

  private identifyAIPackages(dependencies: Dependency[]) {
    const aiKeywords = [
      'tensorflow', 'pytorch', 'keras', 'scikit-learn', 'sklearn',
      'transformers', 'huggingface', 'openai', 'anthropic',
      'langchain', 'llama', 'bert', 'gpt',
      'xgboost', 'lightgbm', 'catboost',
      'opencv', 'pillow', 'torchvision',
      'spacy', 'nltk', 'gensim'
    ];

    return dependencies
      .filter(dep => aiKeywords.some(kw => dep.name.toLowerCase().includes(kw)))
      .map(dep => ({
        ...dep,
        category: this.categorizeAIPackage(dep.name),
        explainability: this.hasExplainability(dep.name)
      }));
  }

  private categorizeAIPackage(packageName: string): string {
    const name = packageName.toLowerCase();
    
    if (name.includes('tensorflow') || name.includes('pytorch') || name.includes('keras')) {
      return 'Deep Learning Framework';
    }
    if (name.includes('sklearn') || name.includes('xgboost')) {
      return 'Machine Learning';
    }
    if (name.includes('transformers') || name.includes('bert') || name.includes('gpt')) {
      return 'Large Language Model';
    }
    if (name.includes('opencv') || name.includes('pillow')) {
      return 'Computer Vision';
    }
    if (name.includes('spacy') || name.includes('nltk')) {
      return 'Natural Language Processing';
    }
    
    return 'IA - Cat√©gorie √† d√©finir';
  }

  private hasExplainability(packageName: string): boolean {
    const explainabilityPackages = ['shap', 'lime', 'eli5', 'interpret'];
    return explainabilityPackages.some(pkg => packageName.toLowerCase().includes(pkg));
  }

  private generateRiskAssessment(aiPackages: any[]): string {
    let assessment = '### √âvaluation des Risques\n\n';
    
    const highRiskPackages = aiPackages.filter(p => p.riskScore >= 6);
    
    if (highRiskPackages.length > 0) {
      assessment += '‚ö†Ô∏è **Packages √† Risque √âlev√©**:\n\n';
      highRiskPackages.forEach(pkg => {
        assessment += `- **${pkg.name}**: Score ${pkg.riskScore.toFixed(1)}/10\n`;
        assessment += `  - Cat√©gorie: ${pkg.category}\n`;
        assessment += `  - Explainability: ${pkg.explainability ? 'Oui' : 'Non'}\n\n`;
      });
    }
    
    assessment += '### Mesures d\'Att√©nuation\n\n';
    assessment += '- Validation des mod√®les sur datasets diversifi√©s\n';
    assessment += '- Tests de robustesse et d\'adversarial attacks\n';
    assessment += '- Documentation des biais identifi√©s\n';
    assessment += '- Monitoring des performances en production\n';
    assessment += '- M√©canismes de feedback utilisateur\n\n';
    
    return assessment;
  }

  private generateResourceRequirements(aiPackages: any[]): string {
    let resources = '### Comp√©tences Requises\n\n';
    resources += '- Data Scientists / ML Engineers\n';
    resources += '- Experts en √©thique IA\n';
    resources += '- Sp√©cialistes en cybers√©curit√©\n';
    resources += '- Auditeurs de conformit√©\n\n';
    
    resources += '### Infrastructure\n\n';
    resources += '- Environnements de d√©veloppement isol√©s\n';
    resources += '- Pipelines CI/CD pour ML\n';
    resources += '- Monitoring et observabilit√©\n';
    resources += '- Versionning des mod√®les (MLflow, DVC)\n\n';
    
    return resources;
  }

  private generatePerformanceMetrics(aiPackages: any[]): string {
    let metrics = '### M√©triques Cl√©s\n\n';
    metrics += '- **Exactitude (Accuracy)**: % de pr√©dictions correctes\n';
    metrics += '- **Pr√©cision / Rappel**: Pour les syst√®mes de classification\n';
    metrics += '- **Biais**: Disparit√© entre groupes d√©mographiques\n';
    metrics += '- **Latence**: Temps de r√©ponse du mod√®le\n';
    metrics += '- **Drift**: D√©gradation des performances dans le temps\n\n';
    
    return metrics;
  }
}

// ========================
// AI Act Compliance Generator
// ========================

export class AIActGenerator {
  /**
   * G√©n√®re un rapport de conformit√© EU AI Act
   */
  generateReport(dependencies: Dependency[]): string {
    const aiPackages = this.identifyAIPackages(dependencies);
    
    let report = '# üá™üá∫ Rapport de Conformit√© EU AI Act\n\n';
    report += `*G√©n√©r√© le ${new Date().toLocaleString()}*\n\n';
    
    report += '## Classification des Risques AI Act\n\n';
    
    const riskClassification = this.classifyAIRisks(aiPackages);
    
    report += '### Syst√®mes √† Risque Inacceptable üö´\n\n';
    if (riskClassification.unacceptable.length > 0) {
      riskClassification.unacceptable.forEach(pkg => {
        report += `- **${pkg.name}**: ${pkg.reason}\n`;
      });
    } else {
      report += '*Aucun syst√®me identifi√©.*\n';
    }
    report += '\n';
    
    report += '### Syst√®mes √† Haut Risque ‚ö†Ô∏è\n\n';
    if (riskClassification.high.length > 0) {
      riskClassification.high.forEach(pkg => {
        report += `- **${pkg.name}**: ${pkg.reason}\n`;
      });
      report += '\n**Obligations**:\n';
      report += '- Syst√®me de gestion des risques\n';
      report += '- Gouvernance et qualit√© des donn√©es\n';
      report += '- Documentation technique\n';
      report += '- Transparence et information aux utilisateurs\n';
      report += '- Supervision humaine\n';
      report += '- Exactitude, robustesse, cybers√©curit√©\n';
    } else {
      report += '*Aucun syst√®me identifi√©.*\n';
    }
    report += '\n';
    
    report += '### Syst√®mes √† Transparence Requise üìã\n\n';
    if (riskClassification.transparency.length > 0) {
      riskClassification.transparency.forEach(pkg => {
        report += `- **${pkg.name}**: ${pkg.reason}\n`;
      });
      report += '\n**Obligations**:\n';
      report += '- Informer que le contenu est g√©n√©r√© par IA\n';
      report += '- Conception pour √©viter la g√©n√©ration ill√©gale\n';
    } else {
      report += '*Aucun syst√®me identifi√©.*\n';
    }
    report += '\n';
    
    report += '### Syst√®mes √† Risque Minimal ‚úÖ\n\n';
    report += `${riskClassification.minimal.length} package(s) identifi√©(s).\n`;
    report += '*Aucune obligation sp√©cifique.*\n\n';
    
    report += '## Recommandations de Conformit√©\n\n';
    report += this.generateComplianceRecommendations(riskClassification);
    
    return report;
  }

  private identifyAIPackages(dependencies: Dependency[]) {
    const aiKeywords = [
      'tensorflow', 'pytorch', 'keras', 'sklearn',
      'transformers', 'openai', 'anthropic', 'langchain',
      'opencv', 'face-recognition', 'spacy', 'nltk',
      'recommendation', 'ranking'
    ];

    return dependencies.filter(dep => 
      aiKeywords.some(kw => dep.name.toLowerCase().includes(kw))
    );
  }

  private classifyAIRisks(aiPackages: Dependency[]) {
    const classification = {
      unacceptable: [] as Array<{ name: string; reason: string }>,
      high: [] as Array<{ name: string; reason: string }>,
      transparency: [] as Array<{ name: string; reason: string }>,
      minimal: [] as Array<{ name: string }>
    };

    aiPackages.forEach(pkg => {
      const name = pkg.name.toLowerCase();
      
      // Risque inacceptable (ex: notation sociale, manipulation comportementale)
      if (name.includes('social-score') || name.includes('manipulation')) {
        classification.unacceptable.push({
          name: pkg.name,
          reason: 'Potentiel syst√®me de notation sociale'
        });
      }
      // Haut risque (ex: biom√©trie, d√©cisions critiques)
      else if (
        name.includes('face-recognition') ||
        name.includes('emotion') ||
        name.includes('biometric') ||
        name.includes('recruitment') ||
        name.includes('credit-scoring')
      ) {
        classification.high.push({
          name: pkg.name,
          reason: this.getHighRiskReason(name)
        });
      }
      // Transparence (ex: chatbots, g√©n√©ration de contenu)
      else if (
        name.includes('gpt') ||
        name.includes('llm') ||
        name.includes('chatbot') ||
        name.includes('transformer')
      ) {
        classification.transparency.push({
          name: pkg.name,
          reason: 'Syst√®me de g√©n√©ration de contenu / interaction avec utilisateurs'
        });
      }
      // Risque minimal
      else {
        classification.minimal.push({ name: pkg.name });
      }
    });

    return classification;
  }

  private getHighRiskReason(packageName: string): string {
    if (packageName.includes('face') || packageName.includes('biometric')) {
      return 'Identification biom√©trique';
    }
    if (packageName.includes('emotion')) {
      return 'Reconnaissance √©motionnelle';
    }
    if (packageName.includes('recruitment')) {
      return 'Aide au recrutement';
    }
    if (packageName.includes('credit')) {
      return '√âvaluation de solvabilit√©';
    }
    return 'Syst√®me √† haut risque identifi√©';
  }

  private generateComplianceRecommendations(classification: any): string {
    let recommendations = '';
    
    if (classification.high.length > 0) {
      recommendations += '### Pour les Syst√®mes √† Haut Risque\n\n';
      recommendations += '1. **Documentation Technique Compl√®te**\n';
      recommendations += '   - Description du syst√®me et de sa finalit√©\n';
      recommendations += '   - Architecture technique d√©taill√©e\n';
      recommendations += '   - Donn√©es d\'entra√Ænement utilis√©es\n\n';
      
      recommendations += '2. **√âvaluation de Conformit√©**\n';
      recommendations += '   - Auto-√©valuation ou √©valuation tierce\n';
      recommendations += '   - Documentation des tests de performance\n';
      recommendations += '   - √âvaluation des biais\n\n';
      
      recommendations += '3. **Marquage CE et D√©claration UE de Conformit√©**\n\n';
    }
    
    if (classification.transparency.length > 0) {
      recommendations += '### Pour les Syst√®mes √† Transparence Requise\n\n';
      recommendations += '- Informer clairement les utilisateurs qu\'ils interagissent avec une IA\n';
      recommendations += '- √âtiqueter les contenus g√©n√©r√©s par IA (deepfakes, etc.)\n';
      recommendations += '- Documenter les capacit√©s et limitations du syst√®me\n\n';
    }
    
    recommendations += '### Conseils G√©n√©raux\n\n';
    recommendations += '- Mettre en place un registre des syst√®mes IA\n';
    recommendations += '- Former les √©quipes sur les obligations AI Act\n';
    recommendations += '- Surveiller l\'√©volution de la r√©glementation\n';
    recommendations += '- Pr√©voir des audits r√©guliers de conformit√©\n\n';
    
    return recommendations;
  }
}
